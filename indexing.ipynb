{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1bad8a-a68c-4673-b663-b26367ec9b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\anaconda\\lib\\site-packages (24.3.1)\n",
      "Collecting pip\n",
      "  Using cached pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.3.1\n",
      "    Uninstalling pip-24.3.1:\n",
      "      Successfully uninstalled pip-24.3.1\n",
      "Successfully installed pip-25.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be6c995c-bfb6-44eb-bc85-91d0bdd61a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf -q\n",
    "%pip install faiss-cpu -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc678e-c9d0-4249-81d6-2d1890aff26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in d:\\anaconda\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-text-splitters in d:\\anaconda\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: python-dotenv in d:\\anaconda\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: faiss-cpu in d:\\anaconda\\lib\\site-packages (1.11.0)\n",
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-0.32.5-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting llama-cpp-python\n",
      "  Using cached llama_cpp_python-0.3.9.tar.gz (67.9 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in d:\\anaconda\\lib\\site-packages (from langchain-community) (0.3.64)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in d:\\anaconda\\lib\\site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\anaconda\\lib\\site-packages (from langchain-community) (2.0.30)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\anaconda\\lib\\site-packages (from langchain-community) (2.32.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\anaconda\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\anaconda\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\anaconda\\lib\\site-packages (from langchain-community) (8.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\anaconda\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in d:\\anaconda\\lib\\site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\anaconda\\lib\\site-packages (from langchain-community) (0.3.45)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\anaconda\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in d:\\anaconda\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\anaconda\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\anaconda\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\anaconda\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\anaconda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\anaconda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\anaconda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\anaconda\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\anaconda\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\anaconda\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in d:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: certifi in d:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: idna in d:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\anaconda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\lib\\site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\anaconda\\lib\\site-packages (from huggingface_hub) (4.66.4)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in d:\\anaconda\\lib\\site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.3)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Using cached huggingface_hub-0.32.5-py3-none-any.whl (512 kB)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): still running...\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.9-cp312-cp312-win_amd64.whl size=3367802 sha256=16f32209dc0a6136efa764cad56bc3c44f354fbdde13f5e3962ec4ab4267246f\n",
      "  Stored in directory: c:\\users\\gupta\\appdata\\local\\pip\\cache\\wheels\\e9\\22\\42\\98dca29f6195951fae2aa548582827a45306350e282ab30617\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python, huggingface_hub\n",
      "\n",
      "   ------------- -------------------------- 1/3 [llama-cpp-python]\n",
      "   -------------------------- ------------- 2/3 [huggingface_hub]\n",
      "   -------------------------- ------------- 2/3 [huggingface_hub]\n",
      "   ---------------------------------------- 3/3 [huggingface_hub]\n",
      "\n",
      "Successfully installed diskcache-5.6.3 huggingface_hub-0.32.5 llama-cpp-python-0.3.9\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-community langchain-text-splitters python-dotenv faiss-cpu huggingface_hub llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e88dbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa6bfa1-b789-4e57-a350-268ec163f0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from uuid import uuid4\n",
    "import langchain_community\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab55201b-ca29-4cb3-bbf8-0ad3a8f383b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_39968\\420373532.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  loader = PyPDFLoader(\"..\\Downloads\\minor_report_229311262_navya.pdf\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loader = PyPDFLoader(\"..\\Downloads\\minor_report_229311262_navya.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a0cbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "page_content='international studies that highlight how digital exclusion affects access to services, \n",
      "employment, and civic participation for millions of disabled users. \n",
      "Existing assistive technologies, such as JAWS and NVDA for screen reading, or Read&Write \n",
      "for dyslexia support, have demonstrated significant value but suffer from key limitations. They \n",
      "are often device-dependent, require installation and technical setup, and cannot be universally \n",
      "applied across platforms. Similarly, browser extensions and accessibility plugins offer tools like \n",
      "contrast adjustment and font resizing, but they lack contextual awareness and cannot \n",
      "dynamically adapt based on user behavior. \n",
      "Efforts like AccessiWeb, Microsoft's Seeing AI , and the Global Public Inclusive \n",
      "Infrastructure (GPII)  have explored more personalized and inclusive digital ecosystems. \n",
      "However, they are often limited by scope, region -specific content, and lack integration with' metadata={'producer': 'PDFium', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-04-21T01:38:04+05:30', 'author': 'Deepak Sinwar [MU - Jaipur]', 'moddate': '2025-04-26T23:30:09+05:30', 'source': '..\\\\Downloads\\\\minor_report_229311262_navya.pdf', 'total_pages': 24, 'page': 10, 'page_label': '11'}\n",
      "break\n",
      "page_content='Infrastructure (GPII)  have explored more personalized and inclusive digital ecosystems. \n",
      "However, they are often limited by scope, region -specific content, and lack integration with \n",
      "real-time data sources for schemes and jobs. Notably, very few platforms —academic or \n",
      "commercial—have explored accessibility for Parkinson’s disease, where cursor instability and \n",
      "delayed reaction times significantly hamper usability. Research in this space remains niche and \n",
      "often confined to experimental or medical contexts rather than public-facing solutions. \n",
      "No existing solution effectively integrates job and welfare discovery with a dynamic, AI -\n",
      "enhanced accessibility engine , particularly in the Indian socio -political context. Most \n",
      "importantly, none are designed to work out-of-the-box, require no special installation, and \n",
      "function directly on the web for easy access from any device—mobile or desktop. \n",
      "This project seeks to bridge these gaps by combining inclusive design with intelligent' metadata={'producer': 'PDFium', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-04-21T01:38:04+05:30', 'author': 'Deepak Sinwar [MU - Jaipur]', 'moddate': '2025-04-26T23:30:09+05:30', 'source': '..\\\\Downloads\\\\minor_report_229311262_navya.pdf', 'total_pages': 24, 'page': 10, 'page_label': '11'}\n",
      "break\n",
      "page_content='function directly on the web for easy access from any device—mobile or desktop. \n",
      "This project seeks to bridge these gaps by combining inclusive design with intelligent \n",
      "interaction. It brings together data aggregation, AI, and UX best practices to serve a population \n",
      "that has long been underserved in the digital space. More than a websit e, this platform is a \n",
      "movement toward equal opportunity, digital dignity, and technological empathy.' metadata={'producer': 'PDFium', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-04-21T01:38:04+05:30', 'author': 'Deepak Sinwar [MU - Jaipur]', 'moddate': '2025-04-26T23:30:09+05:30', 'source': '..\\\\Downloads\\\\minor_report_229311262_navya.pdf', 'total_pages': 24, 'page': 10, 'page_label': '11'}\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200,\n",
    ") \n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "print(len(splitted_docs))\n",
    "print(splitted_docs[20])\n",
    "print(\"break\")\n",
    "print(splitted_docs[21])\n",
    "print(\"break\")\n",
    "print(splitted_docs[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030a8650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gupta/.lmstudio/models/TheBloke/Llama-2-7B-Chat-GGUF/llama-2-7b-chat.Q4_K_S.gguf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/Users/gupta/.lmstudio/models/TheBloke/Llama-2-7B-Chat-GGUF/llama-2-7b-chat.Q4_K_S.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e02bb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_39968\\1388422152.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.015495951287448406, -0.007061666809022427, -0.01329064927995205, 0.020573776215314865, 0.03226228803396225]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "text = \"This is just for test.\"\n",
    "embedding = embeddings_model.embed_query(text)\n",
    "print(embedding[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637f2594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_39968\\1238617917.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  loader = PyPDFLoader(\"..\\Downloads\\minor_report_229311262_navya.pdf\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (58, 384)\n"
     ]
    }
   ],
   "source": [
    "#load\n",
    "loader = PyPDFLoader(\"..\\Downloads\\minor_report_229311262_navya.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "#chunks\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200,\n",
    ") \n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "#embeddings\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = embeddings_model.embed_documents([chunk.page_content for chunk in chunks])\n",
    "print(f\"Embeddings shape: {len(embeddings), len(embeddings[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1084f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = FAISS.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=embeddings_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb2469d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after turning on the server in lmstudio and copying the address of the server \n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://10.5.0.2:1234/v1\",\n",
    "    api_key=\"lm-studio\", \n",
    "    model=\"llama-2-7b-chat\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1d675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Answer:\n",
      "The topic of this report appears to be a project on developing an AI-driven integrated web platform for specially-abled individuals, with the goal of making access to opportunity seamless, dignified, and empowering.\n",
      "\n",
      "📚 Source Docs:\n",
      "• ..\\Downloads\\minor_report_229311262_navya.pdf\n",
      "• ..\\Downloads\\minor_report_229311262_navya.pdf\n",
      "• ..\\Downloads\\minor_report_229311262_navya.pdf\n",
      "• ..\\Downloads\\minor_report_229311262_navya.pdf\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "def format_query(user_question: str):\n",
    "    return f\"\"\"[INST] <<SYS>>\n",
    "You are a helpful assistant.\n",
    "<</SYS>>\n",
    "{user_question}\n",
    "[/INST]\"\"\"\n",
    "\n",
    "#The RAG Chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vector_db.as_retriever(),\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# 8. Ask a question\n",
    "query = format_query(\"What is the topic of this report?\")\n",
    "result = rag_chain.invoke({\"query\": query})\n",
    "\n",
    "# 9. Show results\n",
    "print(result['result'])\n",
    "\n",
    "print(\"\\n📚 Source Docs:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(\"•\", doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2a305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
